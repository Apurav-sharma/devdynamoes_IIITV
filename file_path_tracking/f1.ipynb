{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: File --f=c:\\Users\\Apurav\\AppData\\Roaming\\jupyter\\runtime\\kernel-v3547266b36a9688219f9d355cf4979bfd3a3c655e.json not found\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import sys\n",
    "from pathlib import Path\n",
    "from collections import defaultdict\n",
    "\n",
    "def find_linked_files(file_content, current_file_path):\n",
    "    \"\"\"\n",
    "    Parse file content and find all linked local files.\n",
    "    Returns a list of resolved absolute paths.\n",
    "    \"\"\"\n",
    "    current_file = os.path.abspath(current_file_path)\n",
    "    current_dir = os.path.dirname(current_file)\n",
    "    \n",
    "    # Enhanced regex to handle various import formats\n",
    "    import_pattern = re.compile(r\"\"\"\n",
    "        (?:import|export)\\s+                     # import or export keyword\n",
    "        (?:(?:[\\w*\\s{},]*)\\s+from\\s+)?          # optional from clause\n",
    "        ['\"]([^'\"]+)['\"]                        # the actual path in quotes\n",
    "    \"\"\", re.VERBOSE)\n",
    "    \n",
    "    linked_files = []\n",
    "    linked_paths = []\n",
    "    \n",
    "    for match in import_pattern.findall(file_content):\n",
    "        import_path = match.strip()\n",
    "        \n",
    "        # Skip external modules (React, Next.js, Axios, etc.)\n",
    "        if not import_path.startswith((\".\", \"/\")):\n",
    "            continue\n",
    "        \n",
    "        linked_paths.append(import_path)\n",
    "        \n",
    "        if import_path.startswith(\"/\"):\n",
    "            import_path = \".\" + import_path\n",
    "        \n",
    "        # Resolve path relative to the current file\n",
    "        abs_path = os.path.normpath(os.path.join(current_dir, import_path))\n",
    "        # print(abs_path)\n",
    "        \n",
    "        # Handle directory imports with index files\n",
    "        if os.path.isdir(abs_path):\n",
    "            for index_file in [\"index.js\", \"index.jsx\", \"index.ts\", \"index.tsx\"]:\n",
    "                index_path = os.path.join(abs_path, index_file)\n",
    "                if os.path.exists(index_path):\n",
    "                    linked_files.append((import_path, index_path))\n",
    "                    break\n",
    "            continue\n",
    "        \n",
    "        # Check if file exists with or without extension\n",
    "        if os.path.exists(abs_path):\n",
    "            linked_files.append((import_path, abs_path))\n",
    "            continue\n",
    "            \n",
    "        # Try adding extensions if the file doesn't exist directly\n",
    "        valid_extensions = [\".js\", \".jsx\", \".ts\", \".tsx\"]\n",
    "        for ext in valid_extensions:\n",
    "            if os.path.exists(abs_path + ext):\n",
    "                linked_files.append((import_path, abs_path + ext))\n",
    "                break\n",
    "    \n",
    "    return linked_paths, linked_files\n",
    "\n",
    "def find_api_endpoints(file_content):\n",
    "    \"\"\"\n",
    "    Extract all API endpoints used in axios calls or fetch requests.\n",
    "    \"\"\"\n",
    "    # Pattern for axios calls like axios.get('/api/...')\n",
    "    axios_pattern = re.compile(r\"\"\"\n",
    "        axios\\.(get|post|put|delete|patch)\\s*\\(\\s*\n",
    "        (?:\n",
    "            [`'\"]([^`'\"]+)[`'\"]|  # Standard string\n",
    "            `([^`]+)`             # Template string without variables\n",
    "        )\n",
    "    \"\"\", re.VERBOSE)\n",
    "    \n",
    "    # Pattern for template strings with variables like `/api/user/${id}`\n",
    "    template_pattern = re.compile(r\"\"\"\n",
    "        axios\\.(get|post|put|delete|patch)\\s*\\(\\s*\n",
    "        `([^`]+)`                 # Template string with variables\n",
    "    \"\"\", re.VERBOSE)\n",
    "    \n",
    "    endpoints = []\n",
    "    \n",
    "    # Find standard axios calls\n",
    "    for match in axios_pattern.findall(file_content):\n",
    "        method, endpoint1, endpoint2 = match\n",
    "        endpoint = endpoint1 or endpoint2\n",
    "        if endpoint and endpoint.startswith('/api/'):\n",
    "            endpoints.append((method, endpoint))\n",
    "    \n",
    "    # Find template string endpoints and extract variables\n",
    "    for match in template_pattern.findall(file_content):\n",
    "        method, template = match\n",
    "        if '${' in template and template.startswith('/api/'):\n",
    "            # Extract template variables\n",
    "            var_pattern = re.compile(r'\\${([^}]+)}')\n",
    "            variables = var_pattern.findall(template)\n",
    "            \n",
    "            endpoints.append((method, template, variables))\n",
    "    \n",
    "    return endpoints\n",
    "\n",
    "def load_file_content(file_path):\n",
    "    \"\"\"Load file content from specified path\"\"\"\n",
    "    try:\n",
    "        with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "            return f.read()\n",
    "    except Exception as e:\n",
    "        print(f\"Error reading file {file_path}: {e}\")\n",
    "        return None\n",
    "\n",
    "def fetch_linked_files_content(file_path):\n",
    "    \"\"\"Fetch content of the main file and all its linked files\"\"\"\n",
    "    content = load_file_content(file_path)\n",
    "    if not content:\n",
    "        return {}\n",
    "    \n",
    "    # Find linked files\n",
    "    linked_paths, linked_files = find_linked_files(content, file_path)\n",
    "    \n",
    "    # Find API endpoints\n",
    "    api_endpoints = find_api_endpoints(content)\n",
    "    \n",
    "    # Create a dictionary with original file content\n",
    "    result = {\n",
    "        file_path: {\n",
    "            \"content\": content,\n",
    "            \"import_paths\": linked_paths,\n",
    "            \"api_endpoints\": api_endpoints\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    # Add content of linked files\n",
    "    for import_path, abs_path in linked_files:\n",
    "        linked_content = load_file_content(abs_path)\n",
    "        if linked_content:\n",
    "            # Recursively analyze each linked file as well\n",
    "            linked_api_endpoints = find_api_endpoints(linked_content)\n",
    "            result[abs_path] = {\n",
    "                \"content\": linked_content,\n",
    "                \"import_path\": import_path,\n",
    "                \"api_endpoints\": linked_api_endpoints\n",
    "            }\n",
    "    \n",
    "    return result\n",
    "\n",
    "def analyze_api_structure(files_data):\n",
    "    \"\"\"\n",
    "    Analyze the API structure based on endpoints used in the files.\n",
    "    \"\"\"\n",
    "    print(files_data)\n",
    "    api_structure = defaultdict(list)\n",
    "    \n",
    "    # Group endpoints by base path\n",
    "    for file_path, data in files_data.items():\n",
    "        if \"api_endpoints\" not in data:\n",
    "            continue\n",
    "            \n",
    "        for endpoint_info in data[\"api_endpoints\"]:\n",
    "            if len(endpoint_info) == 2:  # Standard endpoint\n",
    "                method, endpoint = endpoint_info\n",
    "                parts = endpoint.strip('/').split('/')\n",
    "                if len(parts) > 1:\n",
    "                    base_path = f\"/{parts[0]}/{parts[1]}\"\n",
    "                    api_structure[base_path].append({\n",
    "                        \"method\": method,\n",
    "                        \"endpoint\": endpoint,\n",
    "                        \"file\": file_path,\n",
    "                        \"dynamic\": False\n",
    "                    })\n",
    "            else:  # Template string with variables\n",
    "                method, endpoint, variables = endpoint_info\n",
    "                parts = endpoint.strip('/').split('/')\n",
    "                if len(parts) > 1:\n",
    "                    base_path = f\"/{parts[0]}/{parts[1]}\"\n",
    "                    api_structure[base_path].append({\n",
    "                        \"method\": method,\n",
    "                        \"endpoint\": endpoint,\n",
    "                        \"variables\": variables,\n",
    "                        \"file\": file_path,\n",
    "                        \"dynamic\": True\n",
    "                    })\n",
    "    \n",
    "    return api_structure\n",
    "\n",
    "def main():\n",
    "    # Get file path from command line or use default\n",
    "    if len(sys.argv) > 1:\n",
    "        file_path = sys.argv[1]\n",
    "    else:\n",
    "        # Using the file from the example\n",
    "        file_path = \"test.js\"\n",
    "    \n",
    "    # Ensure the file exists\n",
    "    if not os.path.exists(file_path):\n",
    "        print(f\"Error: File {file_path} not found\")\n",
    "        return\n",
    "    \n",
    "    # Fetch all linked files and their content\n",
    "    files_data = fetch_linked_files_content(file_path)\n",
    "    \n",
    "    # Analyze API structure\n",
    "    api_structure = analyze_api_structure(files_data)\n",
    "    \n",
    "    # Print results\n",
    "    print(f\"\\n🔍 Analysis of {file_path}:\\n\")\n",
    "    \n",
    "    # Print main file imports\n",
    "    main_imports = files_data[file_path]['import_paths']\n",
    "    print(f\"📁 Found {len(main_imports)} local imports:\")\n",
    "    for path in main_imports:\n",
    "        print(f\"  ↪ {path}\")\n",
    "    \n",
    "    # Print linked files content\n",
    "    linked_files = [path for path in files_data if path != file_path]\n",
    "    print(f\"\\n📂 Resolved {len(linked_files)} linked files:\")\n",
    "    for abs_path in linked_files:\n",
    "        data = files_data[abs_path]\n",
    "        print(f\"\\n✅ {data['import_path']} → {abs_path}\")\n",
    "        print(f\"   File size: {len(data['content'])} characters\")\n",
    "        # Print a small preview of the file content\n",
    "        preview = data['content'][:100].replace('\\n', ' ').strip()\n",
    "        if len(data['content']) > 100:\n",
    "            preview += \"...\"\n",
    "        print(f\"   Preview: {preview}\")\n",
    "    \n",
    "    # Print API endpoints\n",
    "    all_endpoints = sum(len(data.get(\"api_endpoints\", [])) for data in files_data.values())\n",
    "    print(f\"\\n🌐 Found {all_endpoints} API endpoints across all files:\")\n",
    "    \n",
    "    for base_path, endpoints in api_structure.items():\n",
    "        print(f\"\\n  API Group: {base_path}\")\n",
    "        for endpoint_info in endpoints:\n",
    "            method = endpoint_info[\"method\"].upper()\n",
    "            endpoint = endpoint_info[\"endpoint\"]\n",
    "            file = os.path.basename(endpoint_info[\"file\"])\n",
    "            \n",
    "            if endpoint_info[\"dynamic\"]:\n",
    "                variables = \", \".join(endpoint_info[\"variables\"])\n",
    "                print(f\"    {method} {endpoint} (dynamic, vars: {variables}) - in {file}\")\n",
    "            else:\n",
    "                print(f\"    {method} {endpoint} - in {file}\")\n",
    "    \n",
    "    # Print missing files\n",
    "    missing_files = [\n",
    "        path for path in main_imports \n",
    "        if not any(data.get('import_path') == path for _, data in files_data.items() if _ != file_path)\n",
    "    ]\n",
    "    \n",
    "    if missing_files:\n",
    "        print(f\"\\n⚠️ Could not resolve {len(missing_files)} files:\")\n",
    "        for path in missing_files:\n",
    "            print(f\"  ❌ {path}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
